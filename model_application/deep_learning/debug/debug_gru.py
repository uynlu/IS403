import torch.nn as nn
import torch

from model_application.deep_learning.model import GRU


class DebugLSTM(nn.Module):
    def __init__(
        self, 
        input_size: int,
        hidden_size: int = 1024,
        num_layers: int = 12,
        dropout_prob: float = 0.3,
        n_steps: int = 1
    ):
        super().__init__()
        
        self.model = GRU(
            input_size=input_size,
            hidden_size=hidden_size,
            num_layers=num_layers,
            dropout_prob=dropout_prob,
            n_steps=n_steps
        )

    def forward(self, input, target):
        print(f"ðŸ”¹ [STEP 0] Input input.shape: {input.shape}")  # (batch_size, features)
        print(f"ðŸ”¹ [STEP 0] Input target.shape: {target.shape}")  # (batch_size, )
        
        output = self.model(input)
        print(f"ðŸ”¹ [STEP 1] Output output.shape: {output.shape}")
        
        return output

# Cáº¥u hÃ¬nh LSTM
input_size = 58
n_steps = 1

device = "cuda" if torch.cuda.is_available() else "cpu"

# Khá»Ÿi táº¡o mÃ´ hÃ¬nh
model = DebugLSTM(input_size=input_size, n_steps=n_steps).to(device)

# ====== Dá»¯ liá»‡u giáº£ láº­p má»›i ======
batch_size = 4
time_steps = 30
features = 58

# Táº¡o input ngáº«u nhiÃªn (batch_size, time_steps, num_features)
input = torch.randn(batch_size, time_steps, features).to(device)

# Táº¡o target ngáº«u nhiÃªn (batch_size, n_steps)
target = torch.randint(100000, 40000000, (batch_size, n_steps)).to(device)

# ====== Cháº¡y thá»­ model ======
output = model(input, target)

# ====== In káº¿t quáº£ ======
print(f"âœ… Output shapes: {[o.shape if o is not None else 'None' for o in output]}")  
